# ğŸ§  Automated Event Recall Assessment
EventRecall is an open-source tool for automating event segmentation and recall assessments using LLMs and sentence embeddings. It provides a scalable and efficient method to investigate event segmentation and recall accuracy, supporting both research and applied cognitive science applications.

This repository contains data and scripts used for:\
**Panela, R. A.**, Barnett, A. J., Barense, M. D., & Herrmann, B. (2025). Event Segmentation Applications in Large Language Model Enabled Automated Recall Assessments (Version 1). *arXiv*. https://doi.org/10.48550/ARXIV.2502.13349

---

## ğŸš€ Features

- âœ… Segment events from narrative and recall files using OpenAI or Meta
- âœ… Evaluate recall accuracy using embedding-based similarity
- âœ… Output results as CSV files and/or visual heatmaps
- âœ… Flexible usage via Python API (CLI support planned)
- âœ… Includes data for revaluation

---

## ğŸ“¦ Module Installation

To use the Python tools for segmentation and recall scoring:

```bash
pip install git+https://github.com/ryanapanela/EventRecall.git
```

---

## ğŸ“¥ Clone Repository for Data and Reanalysis

To access all data and scripts used in the manuscript, clone this repository to your local environment:

```bash
git clone https://github.com/ryanapanela/EventRecall.git
cd EventRecall
```

## ğŸ Python API Usage

### ğŸ“˜ Segmentation

```python
from segmentation import run_segmentation

narrative_events = run_segmentation('data/stories/Run.txt', model='gpt-4', api_key='sk-...')
recall_events = run_segmentation('Recall.txt', model='gpt-4', api_key='sk-...')
```

### ğŸ“Š Recall Evaluation

```python
from recall import evaluate_recall

# Evaluate recall using pre-segmented events
results = evaluate_recall(
    narrative_events=narrative_events,
    recall_events=recall_events,
    model_name='sentence-transformers/LaBSE',
    generate_plots=True,
    output_path='recall_results.csv'
)

# Evaluate recall using a file path for recall events
results = evaluate_recall(
    narrative_events=narrative_events,
    recall_path='recall.txt',
    model_name='sentence-transformers/LaBSE',
    generate_plots=True,
    output_path='recall_results.csv'
)

print(results)
```

---

## ğŸ“ Output

- `CSV`: Recall scores for each narrative event
- `Plot`: Optional heatmap of similarity matrix

---

## ğŸ§ª Research Code & Data
All data and analysis scripts used in the accompanying manuscript are available in:
- `data/segmentation` - segmentation data for humans, GPT, and LLaMA
- `data/recall` - recall transcripts and pre-processed narrative recall scores
- `code/segmentation` - segmentation analysis code
- `code/recall` - recall analysis code

Scripts for reproducing automated segmentations using LLMs are available in `code/segmentation/produce_segmentation`. These include:
`gpt_llama_segmentation.py` â€” runs segmentation using GPT-4 or LLaMA
`segmentation_functions.py` â€” helper functions for LLM prompting and text processing

The narratives used in the manuscript are available in `data/stories`.

>*Note:* The segmentation data used in the final analyses may differ slightly from results generated by these scripts due to the non-deterministic nature of LLM outputs (even at low temperature settings). Additionally, outputs from Python were manually reformatted for compatibility with RMarkdown scripts. As such, there is no single linear pipeline from raw narrative to final plot provided in this repository. Instead, we provide all processed data and relevant scripts to enable reanalysis and inspection.

To rerun the analyses:
- Use the Python scripts to regenerate LLM segmentations if desired
- Execute the RMarkdown notebooks for statistical analyses and vizualization
---

## ğŸ§© File Structure

```
EventRecall/
â”‚
â”œâ”€â”€ code/                                    # Analysis notebooks to reproduce results
â”‚   â”œâ”€â”€ recall
â”‚   â””â”€â”€ segmentation
â”‚
â”œâ”€â”€ data/                                   # Pre-processed data used in manuscript analyses
â”‚   â”œâ”€â”€ recall                              
â”‚   â”œâ”€â”€ segmentation
â”‚   â””â”€â”€ stories
â”‚
â”œâ”€â”€ module/                                 # Python package for installation
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ cli.py
â”‚   â”œâ”€â”€ recall.py                              
â”‚   â”œâ”€â”€ segmentation.py                     
â”‚   â””â”€â”€ utils.py       
â”‚                     
â”œâ”€â”€ requirements.txt                        # Dependencies
â”œâ”€â”€ LICENSE
â”œâ”€â”€ README.md                        
â””â”€â”€ setup.py                                # Installation script                                
```

---

## ğŸ” Function Reference

### `run_segmentation(path, model='gpt-4', api_key=None)`
Segments a text file into discrete events using the specified model.

**Returns:** `list[str]`

---

### `evaluate_recall(...)`
Evaluates recall accuracy between narrative and recall events.

**Inputs:**
- `narrative_path` or `narrative_events`
- `recall_path` or `recall_events`
- `model_name`: Embedding model (default: `'sentence-transformers/LaBSE'`)
- `segmentation_model`: LLM used for segmentation
- `api_key`: Required for OpenAI models
- `generate_plots`: Whether to generate heatmaps
- `output_path`: Path to save CSV

**Returns:** `pd.DataFrame` of recall scores

---

### `recall_score(narrative_events, recall_events, model_name)`
Returns detailed recall metrics, including:
- Full recall matrix
- Best matches per event
- Forward and reverse diagonal scores

---

### `recall_matrix(narrative_events, recall_events, model_name)`
Returns the full similarity matrix between each pair of events.

---

### `embedding(text, model_name)`
Generates embeddings for a list of sentences/events.

---

## ğŸ›  Requirements

- Python 3.8+
- `pandas`, `numpy`, `scipy`, `matplotlib`, `seaborn`, `sentence-transformers`
- For LLM support: OpenAI API key

Install dependencies:
```bash
pip install -r requirements.txt
```

---

## ğŸ“‹ License

MIT License Â© 2025 Ryan A. Panela